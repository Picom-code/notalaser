# 3DCNN+ ğŸš€

A modular pipeline for 3D cube regression using Box.com for data storage and PyTorch for model training. ğŸ“¦ğŸ§ 

## Table of Contents ğŸ“š

* [Overview ğŸŒŸ](#overview-ğŸŒŸ)
* [Prerequisites âœ…](#prerequisites-âœ…)
* [Setup ğŸ”§](#setup-ğŸ”§)
* [Part 1: Data Download (box.py) ğŸ“¥](#part-1-data-download-boxpy-ğŸ“¥)
* [Part 2: Model Training (cnnp.py) ğŸ‹ï¸â€â™‚ï¸](#part-2-model-training-cncppy-ğŸ‹ï¸â€â™‚ï¸)
* [How It Works ğŸ”](#how-it-works-ğŸ”)
* [Results ğŸ“ˆ](#results-ğŸ“ˆ)

## Overview ğŸŒŸ

**3DCNN+** is a two-part Python project:

1. **Data Download** (`box.py`): Fetches preprocessed NumPy data from Box.com using the Box Python SDK. ğŸ
2. **Model Training** (`cnnp.py`): Trains a 3D convolutional neural network (`CubeRegressor`) on the downloaded data for voxel-based regression. ğŸ¤–

This README explains how to configure, run, and understand each script. ğŸ“

## Prerequisites âœ…

* Python 3.8 or higher ğŸ
* Dependencies listed in `requirements.txt` ğŸ“¦

Install all requirements with:

```bash
pip install -r requirements.txt
```

## Setup ğŸ”§

1. **Environment Variables**: Create a `.env` or export before running `box.py`:

   ```bash
   export BOX_CLIENT_ID="<your_client_id>" ğŸ”‘
   export BOX_CLIENT_SECRET="<your_client_secret>" ğŸ”’
   export BOX_DEVELOPER_TOKEN="<your_developer_token>" â³
   ```
2. **Project Folder ID**:

   * In `box.py`, set `project1_id` to your Box root folder ID. ğŸ“‚
   * The script auto-discovers subfolders named `code` and `processed`.

## Part 1: Data Download (box.py) ğŸ“¥

This script logs into Box via OAuth2 and downloads the `processed` folder (and all nested files/folders) into `./processed/`. ğŸ—‚ï¸

Run:

````bash
python box.py
``` ğŸ”„

Key functions:
- `get_folder_id_by_name(parent_folder_id, folder_name)`: Finds a subfolder ID by name. ğŸ”
- `download_folder(folder_id, local_path)`: Recursively downloads all files/subfolders. ğŸ”„

After completion, check that `./processed/` contains `.npy` files for all bands and labels. ğŸ“‚âœ…

## Part 2: Model Training (cnnp.py) ğŸ‹ï¸â€â™‚ï¸
This script loads the downloaded `.npy` data, builds a 3D CNN, and trains it. ğŸ“

Run:
```bash
python cnnp.py
``` âš™ï¸

### Configuration (top of `cnnp.py`)
- `BATCH_SIZE`: samples per batch (adjust for GPU RAM). ğŸ›ï¸
- `BIG_EPOCHS`: number of training epochs. ğŸ”„
- `LEARNING_RATE`: initial learning rate. ğŸšï¸
- `NUM_SAMPLES`: patches sampled per epoch for mini-epochs. ğŸ²

### Dataset ğŸ—„ï¸
- **`PatchDataset`** uses memory-mapped `.npy` arrays to avoid loading everything into RAM. ğŸ§ ğŸ’¾
- It indexes all valid voxel coordinates and extracts 3D patches around each voxel. ğŸ§±

### Model: `CubeRegressor` ğŸ¤–
- A simple 3D CNN with convolutional layers, pooling, adaptive pooling, and a fully connected head. ğŸ§©

### Training Loop ğŸ”„
1. **Compile** model with `torch.compile` for performance. âš™ï¸
2. **Optimizer**: `Adam` with initial `LEARNING_RATE`. ğŸš€
3. **Scheduler**: `ReduceLROnPlateau` on validation loss. ğŸ“‰
4. **Mixed Precision**: `torch.amp.autocast` for faster, memory-efficient training. âš¡
5. **Checkpointing**: Saves weights (`.pth`) each epoch and a loss plot (`loss_plot.png`). ğŸ’¾ğŸ“Š

### Evaluation ğŸ“Š
- After training, computes MSE, MAE, and RÂ² on the validation set and prints results. ğŸ

## How It Works ğŸ”
1. **Authentication & Download**: `box.py` uses OAuth2 to fetch processed data from Box.com. ğŸ”‘
2. **Memory-Mapped Dataset**: Efficiently accesses large NumPy arrays without high RAM usage. ğŸ§ ğŸ’¾
3. **Patch Extraction**: Returns 4D tensors `(batch, channels, D, H, W)` centered on voxels. ğŸ§±
4. **3D CNN**: Processes each patch to output a single regression value. ğŸ¤–
5. **Training Strategy**: Large batch sizes, mini-epochs via sampling, mixed precision, and adaptive LR. ğŸ“ˆ

## Results ğŸ“ˆ
- **Output Directory**: `./checkpoints/` ğŸ“‚
  - Model weights: `epoch_<n>.pth` ğŸ—„ï¸
  - Loss plot: `loss_plot.png` ğŸ“‰
- **Final Metrics** (printed):
  ```text
  Validation MSE: 0.001234, MAE: 0.025678, R2: 0.9123 ğŸ†
````

---

You can adjust script parameters or swap in different models/datasets with minimal changes. ğŸ”„
